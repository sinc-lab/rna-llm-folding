{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYJgiJuPNfSg"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "\n",
        "import os\n",
        "import h5py\n",
        "import pandas as pd\n",
        "import torch as tr\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "print(\"Installing packages...\")\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "!pip install multimolecule > /dev/null 2>&1\n",
        "from multimolecule import RnaTokenizer\n",
        "\n",
        "!git clone --quiet https://github.com/sinc-lab/rna-llm-folding > null\n",
        "os.chdir(\"rna-llm-folding/\")\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03P-HJQdcF1n"
      },
      "outputs": [],
      "source": [
        "# @title Select dataset and RNA-LLM\n",
        "\n",
        "Dataset = \"PDB-RNA\" #@param [\"ArchiveII_kfold\", \"ArchiveII_famfold\", \"bpRNA\", \"bpRNA-new\", \"PDB-RNA\"]\n",
        "dataset_name = Dataset\n",
        "RNA_LLM = \"RNAErnie\" #@param [\"RNAErnie\", \"RNA-FM\", \"RNABERT\", \"RNA-MSM\", \"RiNALMo\", \"ERNIE-RNA\"]\n",
        "model_name = RNA_LLM.lower().replace(\"-\", \"\")\n",
        "\n",
        "llm_path = f\"multimolecule/{model_name}\"\n",
        "\n",
        "print(f\"loading {RNA_LLM}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(llm_path,\n",
        "                                          trust_remote_code=True,\n",
        "                                          cls_token=None, eos_token=None)\n",
        "model = AutoModel.from_pretrained(llm_path, trust_remote_code=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2ypx0nFejUa"
      },
      "outputs": [],
      "source": [
        "# @title Load dataset and generate embeddings\n",
        "\n",
        "# load dataset\n",
        "dataset_name_base = dataset_name.split(\"_\")[0]\n",
        "df = pd.read_csv(f\"data/{dataset_name_base}.csv\", index_col=\"id\")\n",
        "\n",
        "max_len = 512\n",
        "if RNA_LLM==\"RNABERT\":\n",
        "    max_len = 440\n",
        "\n",
        "df[\"len\"] = df.sequence.str.len()\n",
        "df = df[df.len<max_len]\n",
        "\n",
        "# generate embeddings\n",
        "embeddings = {}\n",
        "for k in tqdm(range(len(df))):\n",
        "    id = df.iloc[k].name\n",
        "    sequence = df.iloc[k].sequence\n",
        "    with tr.no_grad():\n",
        "        input = tokenizer(sequence, return_tensors=\"pt\")\n",
        "        output = model(**input)[\"last_hidden_state\"][0, 1:, :]\n",
        "    embeddings[id] = output\n",
        "\n",
        "emb_file = f'data/embeddings/{model_name}_{dataset_name_base}.h5'\n",
        "with h5py.File(emb_file, 'w') as hdf:\n",
        "    print(\"Writing embedding file\", emb_file)\n",
        "    for key, value in embeddings.items():\n",
        "        hdf.create_dataset(key, data=value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dw0w7tmHkk_f"
      },
      "outputs": [],
      "source": [
        "# @title Run scripts for train and test\n",
        "\n",
        "cmd = f\"python scripts/run_{dataset_name.lower()}.py --emb {model_name}_{dataset_name_base}\"\n",
        "print(cmd)\n",
        "!{cmd}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
