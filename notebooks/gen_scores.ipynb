{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XjZQ30r_6iSz",
        "9bT0JqsU6m-l"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "d3vx4Qla6gZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import urllib"
      ],
      "metadata": {
        "id": "rk9DOZrzX-Nn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define paths"
      ],
      "metadata": {
        "id": "XjZQ30r_6iSz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tZpGlCq8WwfZ"
      },
      "outputs": [],
      "source": [
        "REPO_URL=\"https://raw.githubusercontent.com/sinc-lab/rna-llm-folding/refs/heads/main\"\n",
        "DATA_PATH=f\"{REPO_URL}/data\"\n",
        "RESULTS_PATH=f\"{REPO_URL}/results\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Labels and common methods"
      ],
      "metadata": {
        "id": "9bT0JqsU6m-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llms = [\"RiNALMo\", \"ERNIE-RNA\", \"rna-msm\", \"rnabert\", \"rnafm\", \"one-hot\", \"RNAErnie\"]\n",
        "llm_names = {\n",
        "    \"rna-msm\": \"RNA-MSM\",\n",
        "    \"rnafm\": \"RNA-FM\",\n",
        "    \"rnabert\": \"RNABERT\",\n",
        "}"
      ],
      "metadata": {
        "id": "CAew_a6FYh18"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## UTILS from sincFold\n",
        "MATCHING_BRACKETS = [\n",
        "    [\"(\", \")\"],\n",
        "    [\"[\", \"]\"],\n",
        "    [\"{\", \"}\"],\n",
        "    [\"<\", \">\"],\n",
        "    [\"A\", \"a\"],\n",
        "    [\"B\", \"a\"],\n",
        "]\n",
        "\n",
        "def f1_strict(ref_bp, pre_bp):\n",
        "    \"\"\"F1 score strict, same as triangular but less efficient\"\"\"\n",
        "    # corner case when there are no positives\n",
        "    if len(ref_bp) == 0 and len(pre_bp) == 0:\n",
        "        return 1.0, 1.0, 1.0\n",
        "\n",
        "    tp1 = 0\n",
        "    for rbp in ref_bp:\n",
        "        if rbp in pre_bp:\n",
        "            tp1 = tp1 + 1\n",
        "    tp2 = 0\n",
        "    for pbp in pre_bp:\n",
        "        if pbp in ref_bp:\n",
        "            tp2 = tp2 + 1\n",
        "\n",
        "    fn = len(ref_bp) - tp1\n",
        "    fp = len(pre_bp) - tp1\n",
        "\n",
        "    tpr = pre = f1 = 0.0\n",
        "    if tp1 + fn > 0:\n",
        "        tpr = tp1 / float(tp1 + fn)  # sensitivity (=recall =power)\n",
        "    if tp1 + fp > 0:\n",
        "        pre = tp2 / float(tp1 + fp)  # precision (=ppv)\n",
        "    if tpr + pre > 0:\n",
        "        f1 = 2 * pre * tpr / (pre + tpr)  # F1 score\n",
        "\n",
        "    return tpr, pre, f1\n",
        "\n",
        "\n",
        "\n",
        "def fold2bp(struc, xop=\"(\", xcl=\")\"):\n",
        "    \"\"\"Get base pairs from one page folding (using only one type of brackets).\n",
        "    BP are 1-indexed\"\"\"\n",
        "    openxs = []\n",
        "    bps = []\n",
        "    if struc.count(xop) != struc.count(xcl):\n",
        "        return False\n",
        "    for i, x in enumerate(struc):\n",
        "        if x == xop:\n",
        "            openxs.append(i)\n",
        "        elif x == xcl:\n",
        "            if len(openxs) > 0:\n",
        "                bps.append([openxs.pop() + 1, i + 1])\n",
        "            else:\n",
        "                return False\n",
        "    return bps\n",
        "\n",
        "\n",
        "def dot2bp(struc):\n",
        "    bp = []\n",
        "    if not set(struc).issubset(\n",
        "        set([\".\"] + [c for par in MATCHING_BRACKETS for c in par])\n",
        "    ):\n",
        "        return False\n",
        "\n",
        "    for brackets in MATCHING_BRACKETS:\n",
        "        if brackets[0] in struc:\n",
        "            bpk = fold2bp(struc, brackets[0], brackets[1])\n",
        "            if bpk:\n",
        "                bp = bp + bpk\n",
        "            else:\n",
        "                return False\n",
        "    return list(sorted(bp))"
      ],
      "metadata": {
        "id": "0mPZ0fhfYHjw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate kfold F1 scores"
      ],
      "metadata": {
        "id": "DsR9n7mi6qPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_list_kfold(emb_name):\n",
        "  \"\"\"\n",
        "  Method that computes the F1 score for all ArchiveII kfold test partitions\n",
        "  and returns a list of tuples with format <f1 score, LLM name>.\n",
        "  \"\"\"\n",
        "  kfold_list = []\n",
        "  df = pd.read_csv(f'{DATA_PATH}/ArchiveII.csv', index_col=\"id\")\n",
        "  splits = pd.read_csv(f'{DATA_PATH}/ArchiveII_kfold_splits.csv', index_col=\"id\")\n",
        "  for k in range(5):\n",
        "    test = df.loc[splits[(splits.fold==k) & (splits.partition==\"test\")].index]\n",
        "    kfold_results_path = f\"{RESULTS_PATH}/ArchiveII_kfold/{emb_name}/{k}\"\n",
        "    try:\n",
        "      preds = pd.read_csv(f\"{kfold_results_path}/preds.csv\")\n",
        "    except urllib.error.HTTPError:\n",
        "      preds = pd.read_csv(f\"{kfold_results_path}/preds_test.csv\")\n",
        "\n",
        "    ref_bps = test[\"base_pairs\"].tolist()\n",
        "    pred_bps = preds[\"base_pairs\"].tolist()\n",
        "    assert len(ref_bps) == len(pred_bps)\n",
        "\n",
        "    for ref_bp, pred_bp in zip(ref_bps, pred_bps):\n",
        "      _, _, f1 = f1_strict(json.loads(ref_bp), json.loads(pred_bp))\n",
        "      kfold_list.append([f1, llm_names.get(emb_name, emb_name)])\n",
        "  return kfold_list"
      ],
      "metadata": {
        "id": "Q4hTgjNQYLbv"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate famfold F1 scores"
      ],
      "metadata": {
        "id": "keFYzQYu6uCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_list_famfold(emb_name):\n",
        "  \"\"\"\n",
        "  Method that computes the F1 score for ArchiveII famfold partitions\n",
        "  and returns a list of tuples with format <f1 score, LLM name, RNA family>.\n",
        "  \"\"\"\n",
        "  famfold_list = []\n",
        "  df = pd.read_csv(f\"{DATA_PATH}/ArchiveII.csv\")\n",
        "  df[\"fam\"] = df[\"id\"].str.split(\"_\").str[0]\n",
        "  for fam in df[\"fam\"].unique():\n",
        "    fam_path = f\"{RESULTS_PATH}/ArchiveII_famfold/{emb_name}/{fam}\"\n",
        "    try:\n",
        "      preds = pd.read_csv(f\"{fam_path}/preds.csv\")\n",
        "    except urllib.error.HTTPError:\n",
        "      preds = pd.read_csv(f\"{fam_path}/preds_test.csv\")\n",
        "\n",
        "    test = df[df[\"fam\"] == fam]\n",
        "\n",
        "    ref_bps = test[\"base_pairs\"].tolist()\n",
        "    pred_bps = preds[\"base_pairs\"].tolist()\n",
        "    assert len(ref_bps) == len(pred_bps)\n",
        "\n",
        "    for ref_bp, pred_bp in zip(ref_bps, pred_bps):\n",
        "      _, _, f1 = f1_strict(json.loads(ref_bp), json.loads(pred_bp))\n",
        "      famfold_list.append([f1, llm_names.get(emb_name, emb_name), fam])\n",
        "  return famfold_list"
      ],
      "metadata": {
        "id": "yPW_mZQTz7Xi"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate PDB-RNA, bpRNA and bpRNA-new F1 scores"
      ],
      "metadata": {
        "id": "SJ75IOZW6x9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_list(emb_name, dataset):\n",
        "  \"\"\"\n",
        "  Method that computes the F1 score for pdb and bpRNA test partitions\n",
        "  and returns a list of tuples with format <f1 score, LLM name>.\n",
        "  For bpRNA, it also returns a second list with the bpRNA new test partition results.\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(f'{DATA_PATH}/{dataset}.csv', index_col=\"id\")\n",
        "  splits = pd.read_csv(f'{DATA_PATH}/{dataset}_splits.csv', index_col=\"id\")\n",
        "  f1_list = []\n",
        "  f1_list_2 = []\n",
        "\n",
        "  if dataset==\"PDB-RNA\":\n",
        "    test = df.loc[splits.partition==\"test\"]\n",
        "  if dataset==\"bpRNA\":\n",
        "    test = df.loc[splits.partition==\"TS0\"]\n",
        "    new_test = df.loc[splits.partition==\"new\"]\n",
        "\n",
        "  dataset_results_path = f\"{RESULTS_PATH}/{dataset}/{emb_name}\"\n",
        "  try:\n",
        "    preds = pd.read_csv(f\"{dataset_results_path}/preds.csv\")\n",
        "    if dataset==\"bpRNA\":\n",
        "      new_preds = pd.read_csv(f\"{RESULTS_PATH}/{dataset}_new/{emb_name}preds_new_test.csv\")\n",
        "  except urllib.error.HTTPError:\n",
        "    preds = pd.read_csv(f\"{dataset_results_path}/preds_test.csv\")\n",
        "    if dataset==\"bpRNA\":\n",
        "      new_preds = pd.read_csv(f\"{RESULTS_PATH}/{dataset}_new/{emb_name}/preds_new_test.csv\")\n",
        "\n",
        "  ref_bps = test[\"base_pairs\"].tolist()\n",
        "  pred_bps = preds[\"base_pairs\"].tolist()\n",
        "  assert len(ref_bps) == len(pred_bps)\n",
        "\n",
        "  for ref_bp, pred_bp in zip(ref_bps, pred_bps):\n",
        "    _, _, f1 = f1_strict(json.loads(ref_bp), json.loads(pred_bp))\n",
        "    f1_list.append([f1, llm_names.get(emb_name, emb_name)])\n",
        "\n",
        "  if dataset==\"bpRNA\":\n",
        "    ref_bps = new_test[\"base_pairs\"].tolist()\n",
        "    pred_bps = new_preds[\"base_pairs\"].tolist()\n",
        "    assert len(ref_bps) == len(pred_bps)\n",
        "    for ref_bp, pred_bp in zip(ref_bps, pred_bps):\n",
        "      _, _, f1 = f1_strict(json.loads(ref_bp), json.loads(pred_bp))\n",
        "      f1_list_2.append([f1, llm_names.get(emb_name, emb_name)])\n",
        "  return f1_list, f1_list_2"
      ],
      "metadata": {
        "id": "4HaqvglCYMQI"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate baseline F1 for ArchiveII kfold, PDB-RNA, bpRNA and bpRNA-new"
      ],
      "metadata": {
        "id": "AVo3MWZx63k7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_baseline_list(baseline_method, dataset, variant=\"\"):\n",
        "  \"\"\"\n",
        "  Method that computes the baseline F1 scores for Linear Partition C\n",
        "  for PDB-RNA, bpRNA, bpRNA-new and ArchiveII kfold.\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(f'{DATA_PATH}/{dataset}.csv', index_col=\"id\")\n",
        "  splits = pd.read_csv(f'{DATA_PATH}/{dataset}{variant}_splits.csv', index_col=\"id\")\n",
        "\n",
        "  f1_list = []\n",
        "  f1_list_2 = []\n",
        "  if dataset==\"PDB-RNA\":\n",
        "    test = df.loc[splits.partition==\"test\"]\n",
        "  if dataset==\"bpRNA\":\n",
        "    test = df.loc[splits.partition==\"TS0\"]\n",
        "    new_test = df.loc[splits.partition==\"new\"]\n",
        "  if dataset=='ArchiveII':\n",
        "    test = df\n",
        "\n",
        "  preds = pd.read_csv(f\"{RESULTS_PATH}/{dataset}{variant}/{baseline_method}_{dataset}.csv\")\n",
        "  if dataset==\"bpRNA\":\n",
        "    new_preds = pd.read_csv(f\"{RESULTS_PATH}/{dataset}_new/{baseline_method}_{dataset}-new.csv\")\n",
        "\n",
        "  pred_foldings = preds[\"folding\"].tolist()\n",
        "  ref_bps = test[\"base_pairs\"].tolist()\n",
        "  assert len(ref_bps) == len(pred_foldings)\n",
        "\n",
        "  # CONVERT FOLDING TO BP FORMAT\n",
        "  pred_bps = []\n",
        "  for pred_folding in pred_foldings:\n",
        "    pred_bps.append(dot2bp(pred_folding))\n",
        "\n",
        "  for ref_bp, pred_bp in zip(ref_bps, pred_bps):\n",
        "    _, _, f1 = f1_strict(json.loads(ref_bp), pred_bp)\n",
        "    f1_list.append(f1)\n",
        "\n",
        "  if dataset=='bpRNA':\n",
        "    new_pred_foldings = new_preds[\"folding\"].tolist()\n",
        "    ref_bps = new_test[\"base_pairs\"].tolist()\n",
        "    assert len(ref_bps) == len(new_pred_foldings)\n",
        "    new_pred_bps = []\n",
        "    for new_pred_folding in new_pred_foldings:\n",
        "      new_pred_bps.append(dot2bp(new_pred_folding))\n",
        "\n",
        "    for ref_bp, new_pred_bp in zip(ref_bps, new_pred_bps):\n",
        "      _, _, f1 = f1_strict(json.loads(ref_bp), new_pred_bp)\n",
        "      f1_list_2.append(f1)\n",
        "\n",
        "  return f1_list, f1_list_2"
      ],
      "metadata": {
        "id": "_fEGe4AHYNKo"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate baseline F1 for ArchiveII famfold"
      ],
      "metadata": {
        "id": "LOsW_wMEm9Bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_baseline_list_famfold(baseline_method):\n",
        "  \"\"\"\n",
        "  Method that computes the baseline F1 score for Linear Partition C\n",
        "  for ArchiveII fam fold, returing a list of tuples with format <f1 score, family name>\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(f'{DATA_PATH}/ArchiveII.csv')\n",
        "  df[\"fam\"] = df[\"id\"].str.split(\"_\").str[0]\n",
        "  preds = pd.read_csv(f\"{RESULTS_PATH}/ArchiveII_kfold/{baseline_method}_ArchiveII.csv\")\n",
        "  preds[\"fam\"] = preds[\"id\"].str.split(\"_\").str[0]\n",
        "  f1_list = []\n",
        "  for fam in df[\"fam\"].unique():\n",
        "    test = df[df[\"fam\"] == fam]\n",
        "    preds_fam = preds[preds[\"fam\"] == fam]\n",
        "    pred_foldings = preds_fam[\"folding\"].tolist()\n",
        "    ref_bps = test[\"base_pairs\"].tolist()\n",
        "    assert len(ref_bps) == len(pred_foldings)\n",
        "    # CONVERT FOLDING TO BP FORMAT\n",
        "    pred_bps = []\n",
        "    for pred_folding in pred_foldings:\n",
        "      pred_bps.append(dot2bp(pred_folding))\n",
        "    for ref_bp, pred_bp in zip(ref_bps, pred_bps):\n",
        "      _, _, f1 = f1_strict(json.loads(ref_bp), pred_bp)\n",
        "      f1_list.append([f1,fam])\n",
        "  return f1_list"
      ],
      "metadata": {
        "id": "5ryOnI1jKvIC"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save csv files"
      ],
      "metadata": {
        "id": "202RQeRt6-tF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_kfold = []\n",
        "for llm in llms:\n",
        "  all_kfold.extend(make_list_kfold(llm))\n",
        "kfold_df = pd.DataFrame(all_kfold, columns=['F1', 'LLM'])\n",
        "kfold_df.to_csv(\"ArchiveII_kfold_scores.csv\",index=False,header=True)"
      ],
      "metadata": {
        "id": "SIg2z9jHbD0q"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_famfold = []\n",
        "for llm in llms:\n",
        "  all_famfold.extend(make_list_famfold(llm))\n",
        "famfold_df = pd.DataFrame(all_famfold, columns=['F1', 'LLM', 'fam'])\n",
        "famfold_df.to_csv(\"ArchiveII_famfold_scores.csv\",index=False,header=True)"
      ],
      "metadata": {
        "id": "xE2bqlzX4Vr3"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_pdb = []\n",
        "for llm in llms:\n",
        "  llm_pdb, _ = make_list(llm, \"PDB-RNA\")\n",
        "  all_pdb.extend(llm_pdb)\n",
        "pdb_df = pd.DataFrame(all_pdb, columns=['F1', 'LLM'])\n",
        "pdb_df.to_csv(\"pdb-rna_scores.csv\",index=False,header=True)"
      ],
      "metadata": {
        "id": "yw_OYJIUeBJF"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_bpRNA = []\n",
        "all_bpRNA_new = []\n",
        "for llm in llms:\n",
        "  llm_bpRNA, llm_bpRNA_new = make_list(llm, \"bpRNA\")\n",
        "  all_bpRNA.extend(llm_bpRNA)\n",
        "  all_bpRNA_new.extend(llm_bpRNA_new)\n",
        "\n",
        "bprna_df = pd.DataFrame(all_bpRNA, columns=['F1', 'LLM'])\n",
        "bprna_new_df = pd.DataFrame(all_bpRNA_new, columns=['F1', 'LLM'])\n",
        "bprna_df.to_csv(\"bpRNA_scores.csv\",index=False,header=True)\n",
        "bprna_new_df.to_csv(\"bpRNA_new_scores.csv\",index=False,header=True)"
      ],
      "metadata": {
        "id": "ONIldLz2cBAU"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_kfold, _ = make_baseline_list(\"linearpartitionC\", \"ArchiveII\", \"_kfold\")\n",
        "baseline_kfold_df = pd.DataFrame(baseline_kfold, columns=['F1'])\n",
        "baseline_kfold_df.to_csv(\"ArchiveII_baseline_scores.csv\",index=False,header=True)"
      ],
      "metadata": {
        "id": "CBBx4FHWjCnO"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_bprna, baseline_bprna_new = make_baseline_list(\"linearpartitionC\", \"bpRNA\")\n",
        "baseline_bprna_df = pd.DataFrame(baseline_bprna, columns=['F1'])\n",
        "baseline_bprna_df.to_csv(\"bpRNA_baseline_scores.csv\",index=False,header=True)\n",
        "baseline_bprna_new_df = pd.DataFrame(baseline_bprna_new, columns=['F1'])\n",
        "baseline_bprna_new_df.to_csv(\"bpRNA_new_baseline_scores.csv\",index=False,header=True)"
      ],
      "metadata": {
        "id": "EHJ9a26bjo0v"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_pdb, _ = make_baseline_list(\"linearpartitionC\", \"PDB-RNA\")\n",
        "baseline_pdb_df = pd.DataFrame(baseline_pdb, columns=['F1'])\n",
        "baseline_pdb_df.to_csv(\"PDB-RNA_baseline_scores.csv\",index=False,header=True)"
      ],
      "metadata": {
        "id": "w5XxwbBdjPa1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_famfold = make_baseline_list_famfold(\"linearpartitionC\")\n",
        "baseline_famfold_df = pd.DataFrame(baseline_famfold, columns=['F1', 'fam'])\n",
        "baseline_famfold_df.to_csv(\"ArchiveII_famfold_baseline_scores.csv\",index=False,header=True)"
      ],
      "metadata": {
        "id": "Ii9dyLZaLVOm"
      },
      "execution_count": 57,
      "outputs": []
    }
  ]
}